[
  {
    "id": "access-2022",
    "badge": "Journal",
    "badgeClass": "ieee",
    "type": "journal",
    "title": "Automatic Emotion Recognition From Multi-Band EEG Data Based on a Deep Learning Scheme With Effective Channel Attention",
    "authors": ["Oishy Saha", "Md. Sultan Mahmud", "Shaikh A. Fattah", "Mohammad Saquib"],
    "venue": "IEEE Access",
    "year": 2023,
    "date": "2023-01-15",
    "volume": "11",
    "pages": "2342â€“2350",
    "doi": "10.1109/ACCESS.2022.3224725",
    "links": {
      "html": "https://ieeexplore.ieee.org/abstract/document/9963974",
      "pdf": "https://drive.google.com/file/d/11qfgizdE2g5A_1mORgU-g6Q66vn9U_O-/view?usp=sharing",
      "code": ""
    },
    "abstract": "Automatic emotion recognition using electroencephalogram (EEG) has obtained a wide range of attention in the domain of human-computer interaction (HCI) owing to the notable differences in brain activities in the event of different types of emotions. In this paper, a novel emotion recognition approach is proposed based on a deep learning scheme utilizing the temporal, spatial, and frequency effects of the EEG signal. As neural firing provides a pathway to elicit emotions, temporal, spatial, and frequency sub-band analysis of EEG signals uncovers salient information to categorize different classes of emotions. In this regard, temporal data from each channel are divided into major spectral bands and 2D signal matrices are constructed by combining the temporal information of different frequency band signals. After concatenating all signal matrices obtained from the available channels, a 3D feature space is obtained, which can better characterize emotion variations and, thus, better classification performance is obtained. The feature space is applied to a 2D deep neural network where the band information is passed to the depth dimension of the neural network. In order to highlight the important channels, a channel attention mechanism is proposed with the neural network to distribute the weights among the channels according to the contribution. Hence, the modified feature space effectively captures distinctive information about specific channels in the context of emotion recognition. In this study, detailed and extensive experimentations are carried out on a publicly available DEAP dataset and a very satisfactory performance is obtained for the valence and the arousal domain in 2-class scenario for the subject-dependent case. The average accuracies obtained for valence and arousal domain in binary class problem are 97.06% and 96.93%, respectively.",
  "bibtex": "@ARTICLE{9963974,\n  author={Saha, Oishy and Mahmud, Md. Sultan and Fattah, Shaikh Anowarul and Saquib, Mohammad},\n  journal={IEEE Access}, \n  title={Automatic Emotion Recognition From Multi-Band EEG Data Based on a Deep Learning Scheme With Effective Channel Attention}, \n  year={2023},\n  volume={11},\n  number={},\n  pages={2342-2350},\n  keywords={Electroencephalography;Feature extraction;Emotion recognition;Deep learning;Brain modeling;Time-frequency analysis;Three-dimensional displays;Electroencephalogram (EEG);brain-computer interface (BCI);frequency bands;channel attention;deep learning},\n  doi={10.1109/ACCESS.2022.3224725}}"
  },
  {
    "id": "bpee-2024",
    "badge": "Journal",
    "badgeClass": "ieee",
    "type": "journal",
    "title": "Emotion Recognition with Reduced Channels Using CWT-Based EEG Feature Representation and a CNN Classifier",
    "authors": ["Md. Sultan Mahmud", "Shaikh A. Fattah", "Md. Saquib", "Oishy Saha"],
    "venue": "Biomedical Physics & Engineering Express",
    "year": 2024,
    "links": {
      "html": "https://iopscience.iop.org/article/10.1088/2057-1976/ad31f9/meta",
      "pdf": "",
      "code": ""
    },
    "abstract": "Objective. Although emotion recognition has been studied for decades, a more accurate classification method that requires less computing is still needed. At present, in many studies, EEG features are extracted from all channels to recognize emotional states, however, there is a lack of an efficient feature domain that improves classification performance and reduces the number of EEG channels. Approach. In this study, a continuous wavelet transform (CWT)-based feature representation of multi-channel EEG data is proposed for automatic emotion recognition. In the proposed feature, the time-frequency domain information is preserved by using CWT coefficients. For a particular EEG channel, each CWT coefficient is mapped into a strength-to-entropy component ratio to obtain a 2D representation. Finally, a 2D feature matrix, namely CEF2D, is created by concatenating these representations from different channels and fed into a deep convolutional neural network architecture. Based on the CWT domain energy-to-entropy ratio, effective channel and CWT scale selection schemes are also proposed to reduce computational complexity. Main results. Compared with previous studies, the results of this study show that valence and arousal classification accuracy has improved in both 3-class and 2-class cases. For the 2-class problem, the average accuracies obtained for valence and arousal dimensions are 98.83% and 98.95%, respectively, and for the 3-class, the accuracies are 98.25% and 98.68%, respectively. Significance. Our findings show that the entropy-based feature of EEG data in the CWT domain is effective for emotion recognition. Utilizing the proposed feature domain, an effective channel selection method can reduce computational complexity.",
    "bibtex": "@article{Mahmud2024BPEE,\n  title={Emotion Recognition with Reduced Channels Using CWT-Based EEG Feature Representation and a CNN Classifier},\n  author={Mahmud, Md. Sakhawat and Fattah, Shaikh A. and Saquib, Md. and Saha, Oishy},\n  journal={Biomedical Physics & Engineering Express},\n  year={2024}\n}"
  },
  {
    "id": "tencon-2020",
    "badge": "Conference",
    "badgeClass": "conf",
    "type": "conference",
    "title": "A Multi-Model Based Ensembling Approach to Detect COVID-19 from Chest X-ray Image",
    "authors": ["Oishy Saha", "J. Tasnim", "M. T. Raihan", "T. Mahmud", "I. Ahmmed", "S. A. Fattah"],
    "venue": "TENCON 2020 - IEEE Region 10 Conference",
    "year": 2020,
    "links": { "html": "https://ieeexplore.ieee.org/abstract/document/9293802", "pdf": "https://drive.google.com/file/d/1bcp_gf4pJntnAV8ICdVP2TLXq1xX4vdp/view?usp=sharing", "code": "" },
    "abstract": "Since the onset of COVID-19, radiographic image analysis coupled with artificial intelligence (AI) has become popular due to insufficient RT-PCR test kits. In this paper, an automated AI-assisted COVID-19 diagnosis scheme is proposed utilizing the ensembling approach of multiple convolutional neural networks (CNNs). Two different strategies have been carried out for ensembling: A feature level fusionbased ensembling method and a decision level ensembling method. Several traditional CNN architectures are tested and finally in the ensembling operation, MobileNet, InceptionV3, DenseNet201, DenseNet121 and Xception are used. To handle the computational complexity of multiple networks, transfer learning strategy is incorporated through ImageNet pre-trained weight initialization. For feature-level ensembling scheme, global averages of the convolutional feature maps generated from multiple networks are aggregated and undergo through fully connected layers for combined optimization. Additionally, for decision level ensembling scheme, final prediction generated from multiple networks are converged into a single prediction by utilizing the maximum voting criterion. Both strategies perform better than any individual network. Outstanding performances have been achieved through extensive experimentation on a public database with 96% accuracy on 3-class (COVID-19/normal/pneumonia) diagnosis and 89.21% on 4-class (COVID-19/normal/viral pneumonia/bacterial pneumonia) diagnosis.",
    "bibtex": "@inproceedings{Saha2020TENCON,\n  title={A Multi-Model Based Ensembling Approach to Detect COVID-19 from Chest X-ray Image},\n  author={Saha, Oishy and Tasnim, J. and Raihan, M. T. and Mahmud, T. and Ahmmed, I. and Fattah, S. A.},\n  booktitle={TENCON 2020 - IEEE Region 10 Conference},\n  year={2020}\n}"
  },
  {
    "id": "wiecon-2022",
    "badge": "Conference",
    "badgeClass": "conf",
    "type": "conference",
    "title": "DEEPSATTNET: An Efficient Deep Neural Network with Self-Attention Mechanism for Emotion Recognition Utilizing EEG Signal",
    "authors": ["Oishy Saha", "Md. Sultan Mahmud","Shaikh Anowarul Fattah"],
    "venue": "IEEE WIECON-ECE",
    "year": 2022,
    "links": { "html": "https://ieeexplore.ieee.org/abstract/document/10150514", "pdf": "https://drive.google.com/file/d/1IyUfhplpOSnpnPoy4-NnS8CBBR83VlaY/view?usp=sharing", "code": "" },
    "abstract": "Emotion analysis by electroencephalogram (EEG) provides vital information about our overall well-being. Analyzing the change in emotional states in response to changes in brain activity has the potential to anticipate the synchronization of attentional, cognitive, and behavioral reactions to emotionally expressive events and hence detect severe mental disorders. This paper proposes an efficient deep learning architecture, DEEPSATTNET, to classify emotions. In contrast to the traditional method, an additional stage for feature extraction is skipped to reduce computational costs. The CNN block of the DEEPSATTNET network captures spatial characteristics from raw EEG data, whereas the LSTM block efficiently encodes significant features over time steps. To acquire the intra-relationship of the extracted feature, the proposed method employs an efficient self-attention mechanism that effectively assigns greater weights to the most relevant information. Finally, the collected feature vector is fed into the dense classifier, which classifies distinct types of emotions. To validate the performance of the proposed architecture, thorough and extensive experimentations are carried out on a publicly available EEG emotion (DEAP) dataset considering mixed subject analysis. For binary class problems, the mean accuracies found for valence and arousal dimensions are 88.65% and 89.24%, respectively.",
    "bibtex": "@inproceedings{Saha2022WIECON,\n  title={DEEPSATTNET: An Efficient Deep Neural Network with Self-Attention Mechanism for Emotion Recognition Utilizing EEG Signal},\n  author={Saha, Oishy and coauthors},\n  booktitle={IEEE WIECON-ECE},\n  year={2022}\n}"
  },
  {
    "id": "icece-2022",
    "badge": "Conference",
    "badgeClass": "conf",
    "type": "conference",
    "title": "An Efficient Bidirectional LSTM-Based Deep Neural Network for Automatic Emotion Recognition Using EEG Signal",
    "authors": ["Md. Sultan Mahmud", "Oishy Saha", "Shaikh Anowarul Fattah"],
    "venue": "International Conference on Electrical, and Computer Engineering (ICECE)",
    "year": 2022,
    "links": { "html": "https://ieeexplore.ieee.org/abstract/document/10088864", "pdf": "https://drive.google.com/file/d/1gYxr5UnKeZz52UGZN0cep_mDbvjJwSNG/view?usp=sharing", "code": "" },
    "abstract": " Since the variations in brain activity provide a pathway for different emotional states, emotion recognition using electroencephalogram (EEG) has embraced a vast research area in the realm of human-computer interaction. This paper proposes a novel deep neural architecture based on bidirectional long short-term memory (BiLSTM) for automated emotion classification. In the proposed scheme, the long-short-term memory (LSTM) blocks effectively capture important information throughout time steps. The deep-stacked bidirectional mechanism attributes essential features in the forward and backward directions for time-series data. Finally, the acquired feature vector is applied to the dense classifier to categorize different emotion classes. In contrast to the conventional method, an additional feature extraction step is eliminated, resulting in a substantially reduced computational complexity. In this work, extensive and detailed experiments are conducted on a widely available dataset, and satisfactory results are obtained for the valence and arousal domains, considering the performance of all subjects. In binary classification performance, the average accuracy for the valence domain is 82.36%, and the average for the arousal domain is 83.10%.",
    "bibtex": "@inproceedings{Saha2022WIECON,\n  title={DEEPSATTNET: An Efficient Deep Neural Network with Self-Attention Mechanism for Emotion Recognition Utilizing EEG Signal},\n  author={Saha, Oishy and coauthors},\n  booktitle={IEEE WIECON-ECE},\n  year={2022}\n}"
  },
  {
    "id": "iccit-2023",
    "badge": "Conference",
    "badgeClass": "conf",
    "type": "conference",
    "title": "Automatic Emotion Recognition from EEG Signal Utilizing Wavelet Packet Node Reconstruction And a CNN Classifier",
    "authors": ["Md. Sultan Mahmud", "Oishy Saha", "Shaikh Anowarul Fattah"],
    "venue": "International Conference on Computing and Information Technology (ICCIT)",
    "year": 2023,
    "links": { "html": "https://ieeexplore.ieee.org/abstract/document/10440995", "pdf": "https://drive.google.com/file/d/1SBPYAkEfh_E2hrs4q7yLa_ttqBw6IaiG/view?usp=sharing", "code": "" },
    "abstract":"Emotion recognition using electroencephalogram (EEG) has encompassed a broad research area in the domain of affective computing since the change of emotional states in response to variations in brain activities. In this paper, a novel emotion recognition approach is proposed employing the wavelet decomposition and node reconstruction of EEG signals. Following the wavelet decomposition of the EEG signal into five different levels, a node reconstruction scheme is employed to reconstruct the signal at each level to retain the original signal length. Subsequently, a 2D matrix is formed by combining the reconstructed signal information at all decomposition levels. In view of incorporating the information of multi-channel EEG signal, a 3D frame is formed combining the 2D matrices acquired from all available channels. The frame is applied as an input to a 2D deep neural network where the signal information at different decomposition levels is passed to the depth dimension of the neural network. The proposed method offers substantial performance in the classification process for the valence and arousal domain considering the performance of all subjects. The average accuracies obtained for valence and arousal domains in binary class problems are 93.06% and 91.93% respectively.",
    "bibtex": "@inproceedings{Mahmud2023ICCIT,\n  title={Automatic Emotion Recognition from EEG Signal Utilizing Wavelet Packet Node Reconstruction And a CNN Classifier},\n  author={Mahmud, Md. Sultan and Saha, Oishy and Fattah, Shaikh Anowarul},\n  booktitle={International Conference on Computing and Information Technology (ICCIT)},\n  year={2023}\n}"
  },
  {
    "id": "icece-2022",
    "badge": "Conference",
    "badgeClass": "conf",
    "type": "conference",
    "title": "DenseLinkNet: A Deep Convolutional Architecture for Automatic Segmentation of Corneal Endothelial Cell",
    "authors": ["Jarin Tasnim", "Barproda Halder", "Oishy Saha", "Talha Ibn Mahmud", "Shahed Ahmed"],
    "venue": "International Conference on Electrical, and Computer Engineering (ICECE)",
    "year": 2022,
    "links": { "html": "https://ieeexplore.ieee.org/abstract/document/10088845", "pdf": "https://drive.google.com/file/d/1JlbZaEj-n4-cuUqFYfb6OfjRFgrxSyQP/view?usp=sharing", "code": "" },
    "abstract":"Corneal endothelium cell provides vital clinical information regarding the health status of the cornea, which is crucial to monitor different corneal diseases. In this regard, segmentation of the corneal endothelial cell plays a significant role in assessing different clinical parameters, like cell density, coefficient of variation, and hexagonality, that aids clinicians in diagnosing different diseases. Since the manual observation process is both time-consuming and susceptible to errors, finding an efficient approach to automate the segmentation task is imperative. In this paper, an encoder-decoder based deep neural architecture, namely DenseLinkNet, is introduced to automate the segmentation process. In the proposed segmentation architecture, DenseNet-201 is used as an encoder, and LinkNet is used as a decoder. The encoder block exploits the output of the convolutional and dense blocks, and the generated feature map gets added with the corresponding decoder block. Following the process, a segmentation head is introduced to conclude the segmentation task. In this work, the publicly available Alizarine dataset is used for experimental purpose. The proposed DenseLinkNet architecture outperforms other segmentation networks with respect to different performance metrics. The network has achieved a dice-score of 76.82% and a Jaccard-index of 62.51%.",
    "bibtex": "@inproceedings{Mahmud2023ICCIT,\n  title={Automatic Emotion Recognition from EEG Signal Utilizing Wavelet Packet Node Reconstruction And a CNN Classifier},\n  author={Mahmud, Md. Sultan and Saha, Oishy and Fattah, Shaikh Anowarul},\n  booktitle={International Conference on Computing and Information Technology (ICCIT)},\n  year={2023}\n}"
  }
]
