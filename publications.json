[
  {
    "id": "access-2022",
    "badge": "Journal",
    "badgeClass": "ieee",
    "type": "journal",
    "title": "Automatic Emotion Recognition From Multi-Band EEG Data Based on a Deep Learning Scheme With Effective Channel Attention",
    "authors": ["Oishy Saha", "Md. Sultan Mahmud", "Shaikh A. Fattah", "Mohammad Saquib"],
    "venue": "IEEE Access",
    "year": 2023,
    "date": "2023-01-15",
    "volume": "11",
    "pages": "2342â€“2350",
    "doi": "10.1109/ACCESS.2022.3224725",
    "links": {
      "html": "https://ieeexplore.ieee.org/abstract/document/9963974",
      "pdf": "",
      "code": ""
    },
    "abstract": "Automatic emotion recognition using electroencephalogram (EEG) has obtained a wide range of attention in the domain of human-computer interaction (HCI) owing to the notable differences in brain activities in the event of different types of emotions. In this paper, a novel emotion recognition approach is proposed based on a deep learning scheme utilizing the temporal, spatial, and frequency effects of the EEG signal. As neural firing provides a pathway to elicit emotions, temporal, spatial, and frequency sub-band analysis of EEG signals uncovers salient information to categorize different classes of emotions. In this regard, temporal data from each channel are divided into major spectral bands and 2D signal matrices are constructed by combining the temporal information of different frequency band signals. After concatenating all signal matrices obtained from the available channels, a 3D feature space is obtained, which can better characterize emotion variations and, thus, better classification performance is obtained. The feature space is applied to a 2D deep neural network where the band information is passed to the depth dimension of the neural network. In order to highlight the important channels, a channel attention mechanism is proposed with the neural network to distribute the weights among the channels according to the contribution. Hence, the modified feature space effectively captures distinctive information about specific channels in the context of emotion recognition. In this study, detailed and extensive experimentations are carried out on a publicly available DEAP dataset and a very satisfactory performance is obtained for the valence and the arousal domain in 2-class scenario for the subject-dependent case. The average accuracies obtained for valence and arousal domain in binary class problem are 97.06% and 96.93%, respectively.",
  "bibtex": "@ARTICLE{9963974,\n  author={Saha, Oishy and Mahmud, Md. Sultan and Fattah, Shaikh Anowarul and Saquib, Mohammad},\n  journal={IEEE Access}, \n  title={Automatic Emotion Recognition From Multi-Band EEG Data Based on a Deep Learning Scheme With Effective Channel Attention}, \n  year={2023},\n  volume={11},\n  number={},\n  pages={2342-2350},\n  keywords={Electroencephalography;Feature extraction;Emotion recognition;Deep learning;Brain modeling;Time-frequency analysis;Three-dimensional displays;Electroencephalogram (EEG);brain-computer interface (BCI);frequency bands;channel attention;deep learning},\n  doi={10.1109/ACCESS.2022.3224725}}"
  },
  {
    "id": "bpee-2024",
    "badge": "Journal",
    "badgeClass": "ieee",
    "type": "journal",
    "title": "Emotion Recognition with Reduced Channels Using CWT-Based EEG Feature Representation and a CNN Classifier",
    "authors": ["Md. Sultan Mahmud", "Shaikh A. Fattah", "Md. Saquib", "Oishy Saha"],
    "venue": "Biomedical Physics & Engineering Express",
    "year": 2024,
    "links": {
      "html": "https://iopscience.iop.org/article/10.1088/2057-1976/ad31f9/meta",
      "pdf": "",
      "code": ""
    },
    "abstract": "Objective. Although emotion recognition has been studied for decades, a more accurate classification method that requires less computing is still needed. At present, in many studies, EEG features are extracted from all channels to recognize emotional states, however, there is a lack of an efficient feature domain that improves classification performance and reduces the number of EEG channels. Approach. In this study, a continuous wavelet transform (CWT)-based feature representation of multi-channel EEG data is proposed for automatic emotion recognition. In the proposed feature, the time-frequency domain information is preserved by using CWT coefficients. For a particular EEG channel, each CWT coefficient is mapped into a strength-to-entropy component ratio to obtain a 2D representation. Finally, a 2D feature matrix, namely CEF2D, is created by concatenating these representations from different channels and fed into a deep convolutional neural network architecture. Based on the CWT domain energy-to-entropy ratio, effective channel and CWT scale selection schemes are also proposed to reduce computational complexity. Main results. Compared with previous studies, the results of this study show that valence and arousal classification accuracy has improved in both 3-class and 2-class cases. For the 2-class problem, the average accuracies obtained for valence and arousal dimensions are 98.83% and 98.95%, respectively, and for the 3-class, the accuracies are 98.25% and 98.68%, respectively. Significance. Our findings show that the entropy-based feature of EEG data in the CWT domain is effective for emotion recognition. Utilizing the proposed feature domain, an effective channel selection method can reduce computational complexity.",
    "bibtex": "@article{Mahmud2024BPEE,\n  title={Emotion Recognition with Reduced Channels Using CWT-Based EEG Feature Representation and a CNN Classifier},\n  author={Mahmud, Md. Sakhawat and Fattah, Shaikh A. and Saquib, Md. and Saha, Oishy},\n  journal={Biomedical Physics & Engineering Express},\n  year={2024}\n}"
  },
  {
    "id": "tencon-2020",
    "badge": "Conference",
    "badgeClass": "arxiv",
    "type": "conference",
    "title": "A Multi-Model Based Ensembling Approach to Detect COVID-19 from Chest X-ray Image",
    "authors": ["Oishy Saha", "J. Tasnim", "M. T. Raihan", "T. Mahmud", "I. Ahmmed", "S. A. Fattah"],
    "venue": "TENCON 2020 - IEEE Region 10 Conference",
    "year": 2020,
    "links": { "html": "https://ieeexplore.ieee.org/abstract/document/9293802", "pdf": "", "code": "" },
    "abstract": "Since the onset of COVID-19, radiographic image analysis coupled with artificial intelligence (AI) has become popular due to insufficient RT-PCR test kits. In this paper, an automated AI-assisted COVID-19 diagnosis scheme is proposed utilizing the ensembling approach of multiple convolutional neural networks (CNNs). Two different strategies have been carried out for ensembling: A feature level fusionbased ensembling method and a decision level ensembling method. Several traditional CNN architectures are tested and finally in the ensembling operation, MobileNet, InceptionV3, DenseNet201, DenseNet121 and Xception are used. To handle the computational complexity of multiple networks, transfer learning strategy is incorporated through ImageNet pre-trained weight initialization. For feature-level ensembling scheme, global averages of the convolutional feature maps generated from multiple networks are aggregated and undergo through fully connected layers for combined optimization. Additionally, for decision level ensembling scheme, final prediction generated from multiple networks are converged into a single prediction by utilizing the maximum voting criterion. Both strategies perform better than any individual network. Outstanding performances have been achieved through extensive experimentation on a public database with 96% accuracy on 3-class (COVID-19/normal/pneumonia) diagnosis and 89.21% on 4-class (COVID-19/normal/viral pneumonia/bacterial pneumonia) diagnosis.",
    "bibtex": "@inproceedings{Saha2020TENCON,\n  title={A Multi-Model Based Ensembling Approach to Detect COVID-19 from Chest X-ray Image},\n  author={Saha, Oishy and Tasnim, J. and Raihan, M. T. and Mahmud, T. and Ahmmed, I. and Fattah, S. A.},\n  booktitle={TENCON 2020 - IEEE Region 10 Conference},\n  year={2020}\n}"
  },
  {
    "id": "wiecon-2022",
    "badge": "Conference",
    "badgeClass": "conf",
    "type": "conference",
    "title": "DEEPSATTNET: An Efficient Deep Neural Network with Self-Attention Mechanism for Emotion Recognition Utilizing EEG Signal",
    "authors": ["Oishy Saha", "et al."],
    "venue": "IEEE WIECON-ECE",
    "year": 2022,
    "links": { "html": "", "pdf": "", "code": "" },
    "abstract": "Placeholder abstract.",
    "bibtex": "@inproceedings{Saha2022WIECON,\n  title={DEEPSATTNET: An Efficient Deep Neural Network with Self-Attention Mechanism for Emotion Recognition Utilizing EEG Signal},\n  author={Saha, Oishy and coauthors},\n  booktitle={IEEE WIECON-ECE},\n  year={2022}\n}"
  }
]
